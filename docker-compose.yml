version: "3.8"

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: proxyai-api
    env_file: .env
    volumes:
      - upload-data:/tmp/uploads
      - results-data:/tmp/results
    depends_on:
      - redis
      - tusd
    ports:
      - "8000:8000"
    command: |
      uvicorn main:app \
        --host 0.0.0.0 \
        --port 8000 \
        --workers ${API_WORKERS}
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL","curl -f http://localhost:8000/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  cpu-worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: proxyai-cpu-worker
    env_file: .env
    volumes:
      - upload-data:/tmp/uploads
      - results-data:/tmp/results
      - diarizer-cache:/tmp/diarizer_cache
    depends_on:
      - redis
    command: |
      celery -A celery_app worker \
        --loglevel=info \
        --concurrency ${CPU_CONCURRENCY} \
        --hostname cpu-worker \
        --queues preprocess_cpu
    restart: unless-stopped
    healthcheck:
      test: ["CMD","celery","-A","celery_app","status"]
      interval: 30s
      timeout: 5s
      retries: 3

  gpu-worker:
    build:
      context: .
      dockerfile: Dockerfile.gpu
    container_name: proxyai-gpu-worker
    env_file: .env
    volumes:
      - upload-data:/tmp/uploads
      - results-data:/tmp/results
      - /path/to/hf_cache_host:/hf_cache:rw
      - ctranslate2-cache:/root/.cache/ctranslate2
    depends_on:
      - redis
    runtime: nvidia
    command: |
      celery -A celery_app worker \
        --loglevel=info \
        --concurrency ${GPU_CONCURRENCY} \
        --hostname gpu-worker \
        --queues preprocess_gpu
    restart: unless-stopped
    healthcheck:
      test: ["CMD","celery","-A","celery_app","status"]
      interval: 30s
      timeout: 5s
      retries: 3

  redis:
    image: redis:7-alpine
    container_name: proxyai-redis
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
    restart: unless-stopped
    healthcheck:
      test: ["CMD","redis-cli","ping"]
      interval: 30s
      timeout: 5s
      retries: 3

  tusd:
    image: tusproject/tusd:latest
    container_name: proxyai-tusd
    restart: unless-stopped
    ports:
      - "1080:1080"
    command:
      - tusd
      - --host=0.0.0.0
      - --port=1080
      - --dir=/data
    volumes:
      - upload-data:/data
    healthcheck:
      test: ["CMD-SHELL","curl -f http://localhost:1080/files || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  flower:
    image: mher/flower:latest
    container_name: proxyai-flower
    env_file: .env
    environment:
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - FLOWER_USER=${FLOWER_USER}
      - FLOWER_PASS=${FLOWER_PASS}
    ports:
      - "5555:5555"
    command: |
      # запускаем Flower через Celery, чтобы binary всегда в PATH
      celery -A celery_app flower \
        --broker=${CELERY_BROKER_URL} \
        --port=5555 \
        ${FLOWER_USER:+--basic_auth=${FLOWER_USER}:${FLOWER_PASS}}
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL","curl -f http://localhost:5555 || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3

  jobs:
    smoke:
      runs-on: ubuntu-latest
      steps:
        - uses: actions/checkout@v3
        - name: Start services
          run: docker-compose up -d --build
        - name: Smoke test API
          run: |
            sleep 10
            curl -f http://localhost:8000/health
        - name: Tear down
          run: docker-compose down

volumes:
  upload-data:
  results-data:
  diarizer-cache:
  ctranslate2-cache:
  redis-data: