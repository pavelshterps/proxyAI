# Dockerfile.gpu

ARG BASE_IMAGE=nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04
FROM ${BASE_IMAGE}

# 1) System deps
RUN apt-get update \
 && apt-get install -y --no-install-recommends \
      python3.10 python3-pip ffmpeg ca-certificates \
 && rm -rf /var/lib/apt/lists/*

# 2) Python libs
WORKDIR /app
COPY requirements.txt .

# 2a) Torch from NVIDIA index
RUN pip3 install --no-cache-dir --upgrade pip \
 && pip3 install --no-cache-dir \
      torch>=2.1.0+cu118 torchvision>=0.16.0+cu118 \
      --extra-index-url https://download.pytorch.org/whl/cu118

# 2b) The rest of the stack
RUN pip3 install --no-cache-dir -r requirements.txt

# 3) Patch CTranslate2 to import transformers (for quantization)
RUN python3 - <<EOF
import ctranslate2, os
path = os.path.join(os.path.dirname(ctranslate2.__file__), "converters", "transformers.py")
with open(path, "r+") as f:
    content = f.read()
    if "import transformers" not in content:
        f.seek(0)
        f.write("import transformers\n" + content)
EOF

# 4) Copy app
COPY . .

# 5) Entrypoint
ENV CELERY_APP=celery_app:celery_app
CMD ["celery", "-A", "celery_app", "worker", "--loglevel=info", "--pool=prefork", "--concurrency=${GPU_CONCURRENCY}", "--hostname=gpu-worker", "--queues=preprocess_gpu"]