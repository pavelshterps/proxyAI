# Dockerfile.gpu
ARG BASE_IMAGE=nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04
FROM ${BASE_IMAGE}

# Установка системных зависимостей
RUN apt-get update \
 && apt-get install -y --no-install-recommends \
      python3.10 python3-pip ffmpeg curl git-lfs \
 && git lfs install \
 && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Копируем файл зависимостей
COPY requirements.txt .

# Обновляем pip и ставим PyTorch из NVIDIA index
RUN pip install --no-cache-dir --upgrade pip \
 && pip install --no-cache-dir \
      torch torchvision torchaudio \
      --extra-index-url https://download.pytorch.org/whl/cu118

# Устанавливаем остальное
RUN pip install --no-cache-dir -r requirements.txt

# Патчим CTranslate2-конвертер, чтобы подтянул transformers
RUN python3 - << 'EOF'
import ctranslate2, os
path = os.path.dirname(ctranslate2.__file__) + "/converters/transformers.py"
# вставляем импорт transformers в начало
content = open(path).read()
with open(path, "w") as f:
    f.write("import transformers\n" + content)
EOF

# Копируем код приложения
COPY . .

# По умолчанию запускаем worker
CMD ["celery", "-A", "celery_app", "worker", "--loglevel=info", "--hostname=gpu-worker", "--queues=preprocess_gpu"]