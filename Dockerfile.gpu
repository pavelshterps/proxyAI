# Dockerfile.gpu

# 1) Base image with CUDA
FROM nvidia/cuda:12.2.2-cudnn8-runtime-ubuntu22.04

# 2) Переключение на российские зеркала
RUN sed -i 's|http://archive.ubuntu.com/ubuntu/|http://ru.archive.ubuntu.com/ubuntu/|g' /etc/apt/sources.list && \
    sed -i 's|http://security.ubuntu.com/ubuntu|http://ru.archive.ubuntu.com/ubuntu/|g' /etc/apt/sources.list

# 3) Системные зависимости
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
      python3-pip \
      python3-dev \
      build-essential \
      ffmpeg \
      libsndfile1 \
      git && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app

# 4) Устанавливаем основной стек (FastAPI, Celery и т.д.)
COPY requirements.txt ./
RUN pip3 install --upgrade pip && \
    pip3 install --no-cache-dir -r requirements.txt

# 5) CTranslate2 / Faster-Whisper (без системных зависимостей)
RUN pip3 install --no-cache-dir --no-deps \
      ctranslate2[cuda12]==4.4.0 \
      faster-whisper[cuda12] \
      nvidia-cudnn-cu12==9.* \
      nvidia-cublas-cu12==12.*

# 6) Устанавливаем FS-EEND (клонируем и ставим локально)
RUN git clone https://github.com/hitachi-speech/EEND.git /app/eend && \
    pip install --no-cache-dir /app/eend

# 7) Симлинки для cuDNN/cuBLAS
RUN ln -sf /usr/lib/x86_64-linux-gnu/libcudnn.so.9    /usr/lib/x86_64-linux-gnu/libcudnn.so && \
    ln -sf /usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.9  /usr/lib/x86_64-linux-gnu/libcudnn_ops.so && \
    ln -sf /usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.9  /usr/lib/x86_64-linux-gnu/libcudnn_cnn.so && \
    ldconfig

# 8) Копируем остальной код
COPY . .

# 9) Среда для GPU и Whisper
ENV HUGGINGFACE_CACHE_DIR=/hf_cache \
    WHISPER_DEVICE=cuda \
    WHISPER_COMPUTE_TYPE=float16 \
    TF_FORCE_GPU_ALLOW_GROWTH=true \
    CTRANSFORMER_MAX_CUDA_MEMORY=0.8 \
    LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH

# 10) Запуск GPU-воркера
CMD ["celery", "-A", "tasks", "worker", "--loglevel=info", "--concurrency=1", "--queues=preprocess_gpu"]