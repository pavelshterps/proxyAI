# Dockerfile.gpu — proxyAI v13.4.5.2 → v13.5
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

# 1) Системные утилиты, ffmpeg, curl
RUN apt-get update \
 && apt-get install -y --no-install-recommends \
      python3.10 python3-pip ffmpeg curl \
 && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# 2) Копируем зависимости и устанавливаем PyTorch+CUDA
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip \
 && pip install --no-cache-dir \
      torch torchvision --extra-index-url https://download.pytorch.org/whl/cu118 \
 && pip install --no-cache-dir -r requirements.txt

# 3) Патчим ctranslate2-конвертер, чтобы он мог импортировать transformers
RUN python3 - << 'EOF'
import ctranslate2, os
tf = os.path.join(os.path.dirname(ctranslate2.__file__), "converters/transformers.py")
text = open(tf).read()
open(tf, "w").write("import transformers\n" + text)
EOF

# 4) Копируем всё приложение
COPY . .

# 5) Запуск GPU-воркера
CMD ["celery", "-A", "celery_app", "worker", \
     "--loglevel=info", \
     "--concurrency=${GPU_CONCURRENCY}", \
     "--hostname=gpu-worker", \
     "--queues=preprocess_gpu"]